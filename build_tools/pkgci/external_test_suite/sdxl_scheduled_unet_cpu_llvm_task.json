{
  "config_name": "cpu_llvm_task",
  "iree_compile_flags": [
    "--iree-hal-target-backends=llvm-cpu",
    "--iree-llvmcpu-target-cpu-features=host",
    "--iree-input-demote-f64-to-f32",
    // TODO(#17467): Remove the workaround once we have better support for attention op codegen.
    "--iree-llvmcpu-fail-on-large-vector=false"
  ],
  "iree_run_module_flags": [
    "--device=local-task",
    "--parameters=model=real_weights.irpa",
    "--module=sdxl_scheduled_unet_pipeline_fp16_cpu.vmfb",
    "--input=1x4x128x128xf16=@inference_input.0.bin",
    "--input=2x64x2048xf16=@inference_input.1.bin",
    "--input=2x1280xf16=@inference_input.2.bin",
    "--input=1xf16=@inference_input.3.bin",
    "--expected_output=1x4x128x128xf16=@inference_output.0.bin",
    "--expected_f16_threshold=0.8f"
  ],
  "skip_compile_tests": [],
  "skip_run_tests": [],
  "expected_compile_failures": [],
  "expected_run_failures": [
    "sdxl-scheduled-unet-3-tank"
  ]
}
