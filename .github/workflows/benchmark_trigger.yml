# Copyright 2023 The IREE Authors
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: Benchmark trigger

on:
  workflow_dispatch:
  pull_request:
    types:
      - labeled
      - unlabeled
      - edited
  workflow_call:
    inputs:
      runner-group:
        required: true
        type: string
      runner-env:
        required: true
        type: string
      ci-stage:
        required: true
        type: string
      e2e-test-artifacts-dir:
        required: true
        type: string
      e2e-test-artifacts-gcs-artifact-dir:
        required: true
        type: string
      benchmark-tools-gcs-artifact-dir:
        required: true
        type: string

env:
  # This needs to be in env instead of the outputs of setup because it contains
  # the run attempt and we want that to be the current attempt, not whatever
  # attempt the setup step last ran in.
  GCS_DIR: gs://iree-github-actions-${{ github.event_name == 'pull_request' && 'presubmit' || 'postsubmit' }}-artifacts/${{ github.run_id }}/${{ github.run_attempt }}
  HEAD_SHA: ${{ github.event.pull_request.head.sha || github.sha }}
  GUARD_JOB_NAME: fetch_benchmark_presets

jobs:
  # setup:
  #   runs-on: ubuntu-20.04
  #   env:
  #     # The commit being checked out is the merge commit for the PR. Its first
  #     # parent will be the tip of main.
  #     BASE_REF: HEAD^
  #     PR_TITLE: ${{ github.event.pull_request.title }}
  #     PR_BODY: ${{ github.event.pull_request.body }}
  #   outputs:
  #     should-run: ${{ github.event_name == 'pull_request' && steps.configure.outputs.should-run || 'true' }}
  #     ci-stage: ${{ inputs.ci-stage || steps.configure.outputs.ci-stage }}
  #     runner-env: ${{ inputs.runner-env || steps.configure.outputs.runner-env }}
  #     runner-group: ${{ inputs.runner-group || steps.configure.outputs.runner-group }}
  #     benchmark-presets: ${{ inputs.benchmark-presets || steps.configure.outputs.benchmark-presets }}
  #   steps:
  #     - name: "Checking out repository"
  #       if: github.event_name == 'pull_request'
  #       uses: actions/checkout@e2f20e631ae6d7dd3b768f56a5d2af784dd54791 # v2.5.0
  #       with:
  #         # We need the parent commit to do a diff
  #         fetch-depth: 2
  #     - name: "Configuring CI options"
  #       id: configure
  #       if: github.event_name == 'pull_request'
  #       run: |
  #         # Just informative logging. There should only be two commits in the
  #         # history here, but limiting the depth helps when copying from a local
  #         # repo instead of using checkout, e.g. with
  #         # https://github.com/nektos/act where there will be more.
  #         git log --oneline --graph --max-count=3
  #         ./build_tools/github_actions/configure_ci.py

  fetch_benchmark_presets:
    runs-on: ubuntu-20.04
    outputs:
      benchmark-presets: ${{ steps.filter.outputs.benchmark-presets }}
    env:
      PULL_NUMBER: ${{ github.event.number }}
      PR_JSON: pr.json
      COMMENT_JSON: comment.json
      ANNOTATIONS_JSON: annotations.json
    permissions: read-all
    steps:
      - name: Filter description
        id: filter
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh api "/repos/${GITHUB_REPOSITORY}/pulls/${PULL_NUMBER}" > "${PR_JSON}"
          gh api "/repos/${GITHUB_REPOSITORY}/issues/${PULL_NUMBER}/comments" --method GET --paginate -F per_page=100 >  "${COMMENT_JSON}"
          export HEAD_SHA=$(jq --raw-output '.head.sha' "${PR_JSON}")
          export PRESETS=$(jq --raw-output '.body | match("\\s*benchmarks:\\s*(.+)"; "g") | .captures[0].string' "${PR_JSON}")
          echo "pr-head-sha=${HEAD_SHA}" >> "${GITHUB_OUTPUT}"
          echo "benchmark-presets=${PRESETS}" >> "${GITHUB_OUTPUT}"
      # - name: Get previous run
      #   id: get-run
      #   env:
      #     PR_HEAD_SHA: ${{ steps.filter.outputs.pr-hea-sha }}
      #     GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      #   run: |
      #     export ANNOTATIONS_URL=$(gh api \
      #       "/repos/${GITHUB_REPOSITORY}/commits/${PR_HEAD_SHA}/check-runs" \
      #       --method GET \
      #       -F check_name="${GUARD_JOB_NAME}" \
      #       -F filter="latest" \
      #       -F status="completed" \
      #       -F per_page=1 | \
      #       jq --raw-output '.check_runs[0].output.annotations_url')
      #     gh api "${ANNOTATIONS_URL}" > "${ANNOTATIONS_JSON}"

  launch_benchmarks:
    needs: [fetch_benchmark_presets]
    uses: ./.github/workflows/benchmark_execution.yml
    with:
      runner-group: a
      runner-env: b
      ci-stage: c
      e2e-test-artifacts-dir: d
      e2e-test-artifacts-gcs-artifact-dir: e
      benchmark-tools-gcs-artifact-dir: f
      benchmark-presets: ${{ needs.fetch_benchmark_presets.outputs.benchmark-presets }}
