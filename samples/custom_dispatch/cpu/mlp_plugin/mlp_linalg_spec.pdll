#include "mlir/Dialect/Linalg/IR/LinalgOps.td"
#include "mlir/Dialect/Arith/IR/ArithOps.td"
#include "mlir/Dialect/Func/IR/FuncOps.td"
#include "mlir/Dialect/Tensor/IR/TensorOps.td"
#include "mlir/Dialect/Tosa/IR/TosaOps.td"
#include "torch-mlir/Dialect/Torch/IR/TorchOps.td"
#include "torch-mlir/Dialect/TorchConversion/IR/TorchConversionOps.td"


Constraint checkElementType(t1 : Type, t2 : Type);

// Native rewrite "rewriteAsFlowDispatch"
Rewrite rewriteAsFlowDispatch(
        op : Op, fn_name : Attr, 
        inputs : ValueRange, 
        repl_vals : ValueRange, 
        repl_dims : ValueRange, 
        other : ValueRange);


Rewrite BuildMlpOp(replaceOp: Op, lhs : Value, rhs : Value, doReluAttr : Attr) {
  let IntTy = type<"i32">;
  let IndexTy = type<"index">;
  let zeroOp = op<arith.constant> { value = attr<"0 : index"> } -> (IndexTy);
  let oneOp = op<arith.constant> { value = attr<"1 : index"> } -> (IndexTy);
  let m = op<tensor.dim>(lhs, zeroOp) -> (IndexTy);
  let n = op<tensor.dim>(rhs, oneOp)  -> (IndexTy);
  let k = op<tensor.dim>(lhs, oneOp); 
  let m_cast = op<arith.index_cast>(m)  -> (IntTy);
  let n_cast = op<arith.index_cast>(n) -> (IntTy);
  let k_cast = op<arith.index_cast>(k) -> (IntTy);



  let doRelu = op<arith.constant> { value = doReluAttr };
  let inputs = (lhs, rhs);
  let repl_vals = (replaceOp.0 );
  let repl_dims = (m.0, n.0);
  let other = (m_cast.0, n_cast.0, k_cast.0, doRelu.0);

  // oof, figuring out i needed to escape the string took too long :( 
  let fn_name = attr<"\"mlp_external\"">;
  rewriteAsFlowDispatch(replaceOp, fn_name, inputs, repl_vals, repl_dims, other);
}

Pattern mlp_linalg with benefit(1) {
  // Types
  let LhsTy = type<"tensor<?x?xf32>">;
  let RhsTy = type<"tensor<?x?xf32>">;
  let MatMulTy = type<"tensor<?x?xf32>">;
  let IntTy = type<"i32">;
  let IndexTy = type<"index">;
  let BoolTy = type<"i1">;
  let FloatTy = type<"f32">;

  // Opt to match against
  let zeroVal = op<arith.constant> { value = attr<"0.000000e+00 : f32"> } -> (FloatTy);
  let fillOp = op<linalg.fill> (zeroVal.0, empty : Value) -> (MatMulTy);
  let matMulOp = op<linalg.matmul> 
                (lhs : Value<LhsTy>, rhs : Value<RhsTy>, fillOp.0) -> (MatMulTy);

  rewrite matMulOp with { BuildMlpOp(matMulOp, lhs, rhs, attr<"0 : i1">); };   
}

Pattern mlp_torch with benefit(1) {
  // Types

  // Opt to match against
  let lhs_torch = op<torch_c.from_builtin_tensor>(lhs : Value);
  let rhs_torch = op<torch_c.from_builtin_tensor>(rhs: Value);
  let matMulOp = op<torch.aten.mm>(lhs_torch.0, rhs_torch.0) -> (MatMulTy : TypeRange);
  let reluOp = op<torch.aten.relu>(matMulOp.0) -> (MatMulTy);
  let castOp = op<torch_c.to_builtin_tensor>(reluOp.0) -> (MatMulTy);


  rewrite reluOp with { BuildMlpOp(castOp, lhs, rhs, attr<"1 : i1">); }; 
}


Pattern mlp_tosa with benefit(1){
  let elemTy = type<"f32">;

  let matMulOp = op<tosa.matmul>(lhs : Value<LhsTy : Type>, rhs : Value<RhsTy : Type>) -> (MatMulTy : Type);
  checkElementType(LhsTy, elemTy);
  checkElementType(RhsTy, elemTy);
  checkElementType(MatMulTy, elemTy);

  let reluOp = op<tosa.clamp>(matMulOp.0) {
    min_int = attr<"0 : i64">,
    max_int = maxIntValue: Attr,
    min_fp = attr<"0.000000e+00 : f32">,
    max_fp = maxFloatValue: Attr
  } -> (ReluTy : Type);

  rewrite matMulOp with {
    let IntTy = type<"i32">;
    let IndexTy = type<"index">;
    let twoOp = op<arith.constant> { value = attr<"2 : index"> } -> (IndexTy);
    let oneOp = op<arith.constant> { value = attr<"1 : index"> } -> (IndexTy);
    let m = op<tensor.dim>(lhs, oneOp) -> (IndexTy);
    let n = op<tensor.dim>(rhs, twoOp)  -> (IndexTy);
    let k = op<tensor.dim>(lhs, twoOp); 
    let m_cast = op<arith.index_cast>(m)  -> (IntTy);
    let n_cast = op<arith.index_cast>(n) -> (IntTy);
    let k_cast = op<arith.index_cast>(k) -> (IntTy);



    let doRelu = op<arith.constant> { value = attr<"1 : i1">};
    let inputs = (lhs, rhs);
    let repl_vals = (reluOp.0 );
    let repl_dims = ();
    let other = (m_cast.0, n_cast.0, k_cast.0, doRelu.0);

    // oof, figuring out i needed to escape the string took too long :( 
    let fn_name = attr<"\"mlp_external\"">;
    rewriteAsFlowDispatch(reluOp, fn_name, inputs, repl_vals, repl_dims, other);
  }; 
}