// Native rewrite "rewriteAsFlowDispatch"
Rewrite rewriteAsFlowDispatch(
        op : Op, fn_name : Attr, 
        inputs : ValueRange, 
        repl_vals : ValueRange, 
        repl_dims : ValueRange, 
        other : ValueRange);


Pattern mlp_linalg with benefit(1) {
  // Types
  let LhsTy = type<"tensor<?x?xf32>">;
  let RhsTy = type<"tensor<?x?xf32>">;
  let MatMulTy = type<"tensor<?x?xf32>">;
  let IntTy = type<"i32">;
  let IndexTy = type<"index">;
  let BoolTy = type<"i1">;
  let FloatTy = type<"f32">;

  // Opt to match against
  let zeroVal = op<arith.constant> { value = attr<"0.000000e+00 : f32"> } -> (FloatTy);
  let fillOp = op<linalg.fill> (zeroVal.0, empty : Value) -> (MatMulTy);
  let matMulOp = op<linalg.matmul> 
                (lhs : Value<LhsTy>, rhs : Value<RhsTy>, fillOp.0) -> (MatMulTy);

  rewrite matMulOp with {
    let zeroOp = op<arith.constant> { value = attr<"0 : index"> } 
      -> (IndexTy);
    let oneOp = op<arith.constant> { value = attr<"1 : index"> } 
      -> (IndexTy);
    let m = op<tensor.dim>(lhs, zeroOp) -> (IndexTy);
    let n = op<tensor.dim>(rhs, oneOp)  -> (IndexTy);
    let k = op<tensor.dim>(lhs, oneOp); 
    let m_cast = op<arith.index_cast>(m)  -> (IntTy);
    let n_cast = op<arith.index_cast>(n) -> (IntTy);
    let k_cast = op<arith.index_cast>(k) -> (IntTy);



    let doRelu = op<arith.constant> { value = attr<"0 : i1">};
    let inputs = (lhs, rhs);
    let repl_vals = (matMulOp.0 );
    let repl_dims = (m.0, n.0);
    let other = (m_cast.0, n_cast.0, k_cast.0, doRelu.0);

    // oof, figuring out i needed to escape the string took too long :( 
    let fn_name = attr<"\"mlp_external\"">;
    rewriteAsFlowDispatch(
      matMulOp, fn_name, 
      inputs, repl_vals, 
      repl_dims, other);
  };
}
